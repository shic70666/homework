{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7ba3bd1230>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from torchsummary import summary # 输出模型信息，计算模型整体参数量\n",
    "from torchviz import make_dot, make_dot_from_trace # 可视化模型前馈的计算图\n",
    "from visdom import Visdom # 可视化学习曲线\n",
    "import time\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Hyper Parameters\n",
    "num_epochs = 3\n",
    "batch_size = 32\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHM_Dataset(Dataset):\n",
    "    \"\"\" Prepare dataset for pytorch\n",
    "        Ref: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, case, data_file, transform): \n",
    "        self.case = case\n",
    "        self.data_file = Path(data_file)\n",
    "        self.data_df = pd.read_json(self.data_file, dtype=np.array)\n",
    "        # self.data = self.data_df.cat()\n",
    "        self.data = self.data_df.stack()\n",
    "        self.labels = pd.DataFrame([self.case,]*self.data_df.shape[0]*self.data_df.shape[1])\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.labels.iloc[index])\n",
    "        feature = np.array(self.data.iloc[index])\n",
    "\n",
    "        # trans1 = transforms.ToTensor()\n",
    "        # feature_tr1 = trans1(feature)\n",
    "        # mean, std = feature_tr1.mean(), feature_tr1.std()\n",
    "        mean, std = feature.mean(), feature.std()\n",
    "\n",
    "        trans2 = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        feature_tr2 = trans2(feature)\n",
    "        # print(f\"feature: {feature.shape}, label: {label.shape}\")\n",
    "        return feature_tr2, label\n",
    "\n",
    "\n",
    "# shmDS = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm01s.json\")\n",
    "# print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target span needs to be 0 to N-1 [Ref: IndexError: Target is out of bounds](https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# trans = transforms.ToTensor()\n",
    "\n",
    "shmDS_1 = SHM_Dataset(0, \"~/Codes/homework/data/SHM/shm01s.json\", trans) # Case 1\n",
    "shmDS_2 = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm02s.json\", trans)\n",
    "shmDS_3 = SHM_Dataset(2, \"~/Codes/homework/data/SHM/shm03s.json\", trans)\n",
    "shmDS_4 = SHM_Dataset(3, \"~/Codes/homework/data/SHM/shm04s.json\", trans)\n",
    "shmDS_5 = SHM_Dataset(4, \"~/Codes/homework/data/SHM/shm05s.json\", trans)\n",
    "shmDS_6 = SHM_Dataset(5, \"~/Codes/homework/data/SHM/shm06s.json\", trans)\n",
    "shmDS_7 = SHM_Dataset(6, \"~/Codes/homework/data/SHM/shm07s.json\", trans)\n",
    "shmDS_8 = SHM_Dataset(7, \"~/Codes/homework/data/SHM/shm08s.json\", trans)\n",
    "shmDS_9 = SHM_Dataset(8, \"~/Codes/homework/data/SHM/shm09s.json\", trans)\n",
    "shmDS = shmDS_1 + shmDS_2 + shmDS_3 + shmDS_4 + shmDS_5 + shmDS_6 + shmDS_7 + shmDS_8 + shmDS_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 24672 samples in the given dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on a single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 16, 16])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(shmDS, batch_size=batch_size, shuffle=True) # split samples into mini-batches and reshuffle the data to reduce overfitting\n",
    "test_loader = DataLoader(shmDS, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "test_features, test_labels = next(iter(test_loader))\n",
    "# train_features = train_features.unsqueeze(dim=1)\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "fig, axis = plt.subplots()\n",
    "axis.imshow(img, cmap=\"gray\")\n",
    "\n",
    "axis.set(title=f\"Label: {label}\", xticks=range(16), yticks=range(16))\n",
    "plt.show()\n",
    "# print(f\"Input features: {img.shape}\\n\\t{img}\")\n",
    "# print(f\"Label: {label.shape}\\n\\t{label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the neural network\n",
    "\n",
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four-layer convolution\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ## by HB\n",
    "        # self.conv1 = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 4, kernel_size=4, padding=1),\n",
    "        #     nn.BatchNorm2d(4),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2))\n",
    "        # self.conv2 = nn.Sequential(\n",
    "        #     nn.Conv2d(4, 8, kernel_size=4, padding=1),\n",
    "        #     nn.BatchNorm2d(8),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2))\n",
    "        # self.fc = nn.Linear(3*3*8, 9)\n",
    "        \n",
    "        ## by Chen\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(32 * 1 * 1, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     for i, (train_features, train_labels) in enumerate(train_loader):\n",
    "#         train_features = Variable(train_features)\n",
    "#         train_features = train_features.float()\n",
    "#         train_labels = Variable(train_labels)\n",
    "\n",
    "#         # Forward + Backward + Optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = cnn(train_features)\n",
    "#         loss = loss_func(outputs, train_labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if (i + 1) % 100 == 0:\n",
    "#             print('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "#                   % (epoch + 1, num_epochs, i + 1, len(shmDS) // batch_size, loss.item()))\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "/var/folders/4z/qqkm946s6p55jwd60wd7w2n40000gn/T/ipykernel_54076/2646359967.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  test_data = Variable(train_features, volatile=True).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [1/0] | Loss: 0.6562 | TR_acc: 0.7812 | TS_acc: 0.7188 | Time: 7.5\n",
      "epoch: [1/0] | Loss: 0.5649 | TR_acc: 0.8219 | TS_acc: 0.7188 | Time: 7.8\n",
      "epoch: [1/0] | Loss: 0.6395 | TR_acc: 0.7891 | TS_acc: 0.7188 | Time: 8.1\n",
      "epoch: [1/0] | Loss: 0.6255 | TR_acc: 0.7969 | TS_acc: 0.7188 | Time: 8.5\n",
      "epoch: [1/0] | Loss: 0.6590 | TR_acc: 0.7719 | TS_acc: 0.7188 | Time: 8.8\n",
      "epoch: [1/0] | Loss: 0.5700 | TR_acc: 0.8078 | TS_acc: 0.7188 | Time: 9.2\n",
      "epoch: [1/0] | Loss: 0.5826 | TR_acc: 0.8141 | TS_acc: 0.7188 | Time: 9.5\n",
      "epoch: [1/0] | Loss: 0.5729 | TR_acc: 0.8219 | TS_acc: 0.7188 | Time: 9.9\n",
      "epoch: [1/0] | Loss: 0.5737 | TR_acc: 0.8078 | TS_acc: 0.7188 | Time: 10.2\n",
      "epoch: [1/0] | Loss: 0.5505 | TR_acc: 0.8125 | TS_acc: 0.7188 | Time: 10.8\n",
      "epoch: [1/0] | Loss: 0.5850 | TR_acc: 0.8031 | TS_acc: 0.7188 | Time: 11.2\n",
      "epoch: [1/0] | Loss: 0.6137 | TR_acc: 0.7984 | TS_acc: 0.7188 | Time: 11.5\n",
      "epoch: [1/0] | Loss: 0.6513 | TR_acc: 0.7875 | TS_acc: 0.7188 | Time: 11.9\n",
      "epoch: [1/0] | Loss: 0.6548 | TR_acc: 0.7844 | TS_acc: 0.7188 | Time: 12.2\n",
      "epoch: [1/0] | Loss: 0.6358 | TR_acc: 0.7719 | TS_acc: 0.7188 | Time: 12.6\n",
      "epoch: [1/0] | Loss: 0.5942 | TR_acc: 0.8031 | TS_acc: 0.7188 | Time: 12.9\n",
      "epoch: [1/0] | Loss: 0.5981 | TR_acc: 0.7797 | TS_acc: 0.7188 | Time: 13.3\n",
      "epoch: [1/0] | Loss: 0.6398 | TR_acc: 0.7594 | TS_acc: 0.7188 | Time: 13.6\n",
      "epoch: [1/0] | Loss: 0.6091 | TR_acc: 0.8016 | TS_acc: 0.7188 | Time: 14.0\n",
      "epoch: [1/0] | Loss: 0.5910 | TR_acc: 0.7859 | TS_acc: 0.7188 | Time: 14.3\n",
      "epoch: [1/0] | Loss: 0.6166 | TR_acc: 0.7922 | TS_acc: 0.7188 | Time: 14.7\n",
      "epoch: [1/0] | Loss: 0.5939 | TR_acc: 0.7969 | TS_acc: 0.7188 | Time: 15.1\n",
      "epoch: [1/0] | Loss: 0.6068 | TR_acc: 0.7969 | TS_acc: 0.7188 | Time: 15.4\n",
      "epoch: [1/0] | Loss: 0.6000 | TR_acc: 0.7828 | TS_acc: 0.7188 | Time: 15.8\n",
      "epoch: [1/0] | Loss: 0.6530 | TR_acc: 0.7781 | TS_acc: 0.7188 | Time: 16.2\n",
      "epoch: [1/0] | Loss: 0.5651 | TR_acc: 0.8156 | TS_acc: 0.7188 | Time: 16.5\n",
      "epoch: [1/0] | Loss: 0.6389 | TR_acc: 0.7906 | TS_acc: 0.7188 | Time: 16.9\n",
      "epoch: [1/0] | Loss: 0.6023 | TR_acc: 0.7734 | TS_acc: 0.7188 | Time: 17.3\n",
      "epoch: [1/0] | Loss: 0.6256 | TR_acc: 0.7828 | TS_acc: 0.7188 | Time: 17.6\n",
      "epoch: [1/0] | Loss: 0.5936 | TR_acc: 0.7937 | TS_acc: 0.7188 | Time: 18.0\n",
      "epoch: [1/0] | Loss: 0.6862 | TR_acc: 0.7703 | TS_acc: 0.7188 | Time: 18.3\n",
      "epoch: [1/0] | Loss: 0.6159 | TR_acc: 0.7812 | TS_acc: 0.7188 | Time: 18.7\n",
      "epoch: [1/0] | Loss: 0.6415 | TR_acc: 0.7609 | TS_acc: 0.7188 | Time: 19.1\n",
      "epoch: [1/0] | Loss: 0.6505 | TR_acc: 0.7609 | TS_acc: 0.7188 | Time: 19.4\n",
      "epoch: [1/0] | Loss: 0.5685 | TR_acc: 0.8078 | TS_acc: 0.7188 | Time: 19.8\n",
      "epoch: [1/0] | Loss: 0.5910 | TR_acc: 0.8078 | TS_acc: 0.7188 | Time: 20.1\n",
      "epoch: [1/0] | Loss: 0.6096 | TR_acc: 0.7984 | TS_acc: 0.7188 | Time: 20.4\n",
      "epoch: [1/0] | Loss: 0.5458 | TR_acc: 0.8000 | TS_acc: 0.7188 | Time: 20.9\n",
      "epoch: [2/1] | Loss: 0.6400 | TR_acc: 0.7797 | TS_acc: 0.7188 | Time: 28.8\n",
      "epoch: [2/1] | Loss: 0.6392 | TR_acc: 0.7797 | TS_acc: 0.7188 | Time: 29.1\n",
      "epoch: [2/1] | Loss: 0.5753 | TR_acc: 0.8063 | TS_acc: 0.7188 | Time: 29.5\n",
      "epoch: [2/1] | Loss: 0.5882 | TR_acc: 0.7922 | TS_acc: 0.7188 | Time: 29.9\n",
      "epoch: [2/1] | Loss: 0.6171 | TR_acc: 0.8016 | TS_acc: 0.7188 | Time: 30.3\n",
      "epoch: [2/1] | Loss: 0.6383 | TR_acc: 0.7859 | TS_acc: 0.7188 | Time: 30.6\n",
      "epoch: [2/1] | Loss: 0.6471 | TR_acc: 0.7719 | TS_acc: 0.7188 | Time: 31.1\n",
      "epoch: [2/1] | Loss: 0.5377 | TR_acc: 0.8047 | TS_acc: 0.7188 | Time: 31.4\n",
      "epoch: [2/1] | Loss: 0.6624 | TR_acc: 0.7812 | TS_acc: 0.7188 | Time: 31.8\n",
      "epoch: [2/1] | Loss: 0.5938 | TR_acc: 0.7984 | TS_acc: 0.7188 | Time: 32.2\n",
      "epoch: [2/1] | Loss: 0.6009 | TR_acc: 0.7875 | TS_acc: 0.7188 | Time: 32.5\n",
      "epoch: [2/1] | Loss: 0.5998 | TR_acc: 0.7937 | TS_acc: 0.7188 | Time: 32.9\n",
      "epoch: [2/1] | Loss: 0.6174 | TR_acc: 0.7906 | TS_acc: 0.7188 | Time: 33.2\n",
      "epoch: [2/1] | Loss: 0.6198 | TR_acc: 0.7828 | TS_acc: 0.7188 | Time: 33.6\n",
      "epoch: [2/1] | Loss: 0.5656 | TR_acc: 0.7984 | TS_acc: 0.7188 | Time: 34.0\n",
      "epoch: [2/1] | Loss: 0.5966 | TR_acc: 0.7828 | TS_acc: 0.7188 | Time: 34.3\n",
      "epoch: [2/1] | Loss: 0.6291 | TR_acc: 0.7875 | TS_acc: 0.7188 | Time: 34.7\n",
      "epoch: [2/1] | Loss: 0.5955 | TR_acc: 0.7797 | TS_acc: 0.7188 | Time: 35.1\n",
      "epoch: [2/1] | Loss: 0.5681 | TR_acc: 0.8250 | TS_acc: 0.7188 | Time: 35.5\n",
      "epoch: [2/1] | Loss: 0.6057 | TR_acc: 0.8078 | TS_acc: 0.7188 | Time: 35.9\n",
      "epoch: [2/1] | Loss: 0.5807 | TR_acc: 0.8125 | TS_acc: 0.7188 | Time: 36.3\n",
      "epoch: [2/1] | Loss: 0.6016 | TR_acc: 0.8109 | TS_acc: 0.7188 | Time: 36.6\n",
      "epoch: [2/1] | Loss: 0.6609 | TR_acc: 0.7688 | TS_acc: 0.7188 | Time: 37.0\n",
      "epoch: [2/1] | Loss: 0.5765 | TR_acc: 0.8078 | TS_acc: 0.7188 | Time: 37.4\n",
      "epoch: [2/1] | Loss: 0.6863 | TR_acc: 0.7641 | TS_acc: 0.7188 | Time: 37.8\n",
      "epoch: [2/1] | Loss: 0.5588 | TR_acc: 0.8172 | TS_acc: 0.7188 | Time: 38.1\n",
      "epoch: [2/1] | Loss: 0.6181 | TR_acc: 0.7828 | TS_acc: 0.7188 | Time: 38.5\n",
      "epoch: [2/1] | Loss: 0.6304 | TR_acc: 0.7859 | TS_acc: 0.7188 | Time: 38.9\n",
      "epoch: [2/1] | Loss: 0.6442 | TR_acc: 0.7656 | TS_acc: 0.7188 | Time: 39.2\n",
      "epoch: [2/1] | Loss: 0.5814 | TR_acc: 0.8047 | TS_acc: 0.7188 | Time: 39.6\n",
      "epoch: [2/1] | Loss: 0.5851 | TR_acc: 0.8016 | TS_acc: 0.7188 | Time: 40.0\n",
      "epoch: [2/1] | Loss: 0.6397 | TR_acc: 0.7859 | TS_acc: 0.7188 | Time: 40.3\n",
      "epoch: [2/1] | Loss: 0.5989 | TR_acc: 0.8063 | TS_acc: 0.7188 | Time: 40.8\n",
      "epoch: [2/1] | Loss: 0.6428 | TR_acc: 0.7766 | TS_acc: 0.7188 | Time: 41.2\n",
      "epoch: [2/1] | Loss: 0.6282 | TR_acc: 0.7766 | TS_acc: 0.7188 | Time: 41.6\n",
      "epoch: [2/1] | Loss: 0.5848 | TR_acc: 0.7969 | TS_acc: 0.7188 | Time: 41.9\n",
      "epoch: [2/1] | Loss: 0.5800 | TR_acc: 0.8031 | TS_acc: 0.7188 | Time: 42.3\n",
      "epoch: [2/1] | Loss: 0.6180 | TR_acc: 0.7906 | TS_acc: 0.7188 | Time: 42.7\n",
      "epoch: [3/2] | Loss: 0.5900 | TR_acc: 0.7750 | TS_acc: 0.7188 | Time: 50.6\n",
      "epoch: [3/2] | Loss: 0.6451 | TR_acc: 0.7953 | TS_acc: 0.7188 | Time: 51.0\n",
      "epoch: [3/2] | Loss: 0.5854 | TR_acc: 0.7891 | TS_acc: 0.7188 | Time: 51.5\n",
      "epoch: [3/2] | Loss: 0.6041 | TR_acc: 0.8016 | TS_acc: 0.7188 | Time: 51.8\n",
      "epoch: [3/2] | Loss: 0.6519 | TR_acc: 0.7875 | TS_acc: 0.7188 | Time: 52.2\n",
      "epoch: [3/2] | Loss: 0.6106 | TR_acc: 0.7875 | TS_acc: 0.7188 | Time: 52.6\n",
      "epoch: [3/2] | Loss: 0.6521 | TR_acc: 0.7937 | TS_acc: 0.7188 | Time: 53.0\n",
      "epoch: [3/2] | Loss: 0.6374 | TR_acc: 0.7688 | TS_acc: 0.7188 | Time: 53.4\n",
      "epoch: [3/2] | Loss: 0.5868 | TR_acc: 0.8000 | TS_acc: 0.7188 | Time: 53.7\n",
      "epoch: [3/2] | Loss: 0.6436 | TR_acc: 0.7781 | TS_acc: 0.7188 | Time: 54.1\n",
      "epoch: [3/2] | Loss: 0.6113 | TR_acc: 0.7906 | TS_acc: 0.7188 | Time: 54.5\n",
      "epoch: [3/2] | Loss: 0.5957 | TR_acc: 0.7953 | TS_acc: 0.7188 | Time: 54.9\n",
      "epoch: [3/2] | Loss: 0.6362 | TR_acc: 0.7828 | TS_acc: 0.7188 | Time: 55.2\n",
      "epoch: [3/2] | Loss: 0.6367 | TR_acc: 0.7766 | TS_acc: 0.7188 | Time: 55.6\n",
      "epoch: [3/2] | Loss: 0.5908 | TR_acc: 0.8031 | TS_acc: 0.7188 | Time: 56.0\n",
      "epoch: [3/2] | Loss: 0.5608 | TR_acc: 0.8313 | TS_acc: 0.7188 | Time: 56.4\n",
      "epoch: [3/2] | Loss: 0.5003 | TR_acc: 0.8266 | TS_acc: 0.7188 | Time: 57.0\n",
      "epoch: [3/2] | Loss: 0.5993 | TR_acc: 0.7891 | TS_acc: 0.7188 | Time: 57.3\n",
      "epoch: [3/2] | Loss: 0.6094 | TR_acc: 0.7937 | TS_acc: 0.7188 | Time: 57.7\n",
      "epoch: [3/2] | Loss: 0.6255 | TR_acc: 0.7891 | TS_acc: 0.7188 | Time: 58.0\n",
      "epoch: [3/2] | Loss: 0.6090 | TR_acc: 0.7781 | TS_acc: 0.7188 | Time: 58.4\n",
      "epoch: [3/2] | Loss: 0.6544 | TR_acc: 0.7937 | TS_acc: 0.7188 | Time: 58.8\n",
      "epoch: [3/2] | Loss: 0.6410 | TR_acc: 0.7859 | TS_acc: 0.7188 | Time: 59.1\n",
      "epoch: [3/2] | Loss: 0.6213 | TR_acc: 0.7875 | TS_acc: 0.7188 | Time: 59.5\n",
      "epoch: [3/2] | Loss: 0.6299 | TR_acc: 0.7781 | TS_acc: 0.7188 | Time: 59.9\n",
      "epoch: [3/2] | Loss: 0.5988 | TR_acc: 0.7953 | TS_acc: 0.7188 | Time: 60.3\n",
      "epoch: [3/2] | Loss: 0.5972 | TR_acc: 0.7906 | TS_acc: 0.7188 | Time: 60.7\n",
      "epoch: [3/2] | Loss: 0.5987 | TR_acc: 0.7891 | TS_acc: 0.7188 | Time: 61.0\n",
      "epoch: [3/2] | Loss: 0.6163 | TR_acc: 0.7891 | TS_acc: 0.7188 | Time: 61.5\n",
      "epoch: [3/2] | Loss: 0.5634 | TR_acc: 0.8047 | TS_acc: 0.7188 | Time: 62.0\n",
      "epoch: [3/2] | Loss: 0.5505 | TR_acc: 0.8203 | TS_acc: 0.7188 | Time: 62.4\n",
      "epoch: [3/2] | Loss: 0.6060 | TR_acc: 0.8000 | TS_acc: 0.7188 | Time: 62.7\n",
      "epoch: [3/2] | Loss: 0.6293 | TR_acc: 0.7969 | TS_acc: 0.7188 | Time: 63.1\n",
      "epoch: [3/2] | Loss: 0.6132 | TR_acc: 0.8016 | TS_acc: 0.7188 | Time: 63.5\n",
      "epoch: [3/2] | Loss: 0.6425 | TR_acc: 0.7672 | TS_acc: 0.7188 | Time: 63.9\n",
      "epoch: [3/2] | Loss: 0.5722 | TR_acc: 0.8078 | TS_acc: 0.7188 | Time: 64.3\n",
      "epoch: [3/2] | Loss: 0.6017 | TR_acc: 0.7812 | TS_acc: 0.7188 | Time: 64.6\n",
      "epoch: [3/2] | Loss: 0.5853 | TR_acc: 0.7984 | TS_acc: 0.7188 | Time: 65.0\n"
     ]
    }
   ],
   "source": [
    "#! Train the model: Visualization of Loss\n",
    "viz = Visdom()\n",
    "#viz.images(train_features[:10],nrow=100)  # visdom可视化部分数据\n",
    "time.sleep(0.5) # 为防止可视化视窗重叠现象，停顿0.5秒\n",
    "test_data = Variable(train_features, volatile=True).float()\n",
    "line = viz.line(np.arange(10)) # 创建线图可视化窗口\n",
    "start_time = time.time() # 起始时间设置\n",
    "time_p, tr_acc, ts_acc, loss_p = [], [], [], [] # 可视化所需数据点\n",
    "text = viz.text(\"<h1>Convolution Nueral Network</h1>\") # 创建可视化数据视窗\n",
    "for epoch in range(num_epochs):\n",
    "    # 由于分批次学习，输出loss为一批平均，需要累积or平均每个batch的loss\n",
    "    sum_loss, sum_acc, sum_step = 0., 0., 0.\n",
    "    \n",
    "    for test_features, test_labels in test_loader:\n",
    "        test_features = Variable(test_features)\n",
    "        test_features = test_features.float()\n",
    "        test_labels = Variable(test_labels)\n",
    "\n",
    "    for i, (train_features, train_labels) in enumerate(train_loader, 1):\n",
    "        train_features = Variable(train_features)\n",
    "        train_features = train_features.float()\n",
    "        train_labels = Variable(train_labels)\n",
    "        \n",
    "        train_out = cnn(train_features)\n",
    "        loss = loss_func(train_out, train_labels) \n",
    "\n",
    "        sum_loss += loss.item()*len(train_labels)\n",
    "        _, pred_tr = torch.max(train_out.data, 1)\n",
    "        sum_acc += sum(pred_tr==train_labels).item()\n",
    "        sum_step += train_labels.size(0)\n",
    "\n",
    "        optimizer.zero_grad()  # 学习反馈\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0: # 每20个batch可视化一下数据\n",
    "            test_out = cnn(test_features)\n",
    "            _, pred_ts = torch.max(test_out.data, 1)\n",
    "\n",
    "            rightnum = pred_ts.eq(test_labels.view_as(pred_ts)).sum().item()\n",
    "            acc =  rightnum/float(test_labels.size(0))\n",
    "            print(\"epoch: [{}/{}] | Loss: {:.4f} | TR_acc: {:.4f} | TS_acc: {:.4f} | Time: {:.1f}\".format(epoch+1, epoch,\n",
    "                                    sum_loss/(sum_step), sum_acc/(sum_step), acc, time.time()-start_time))\n",
    "            # 可视化部分\n",
    "            time_p.append(time.time()-start_time)\n",
    "            tr_acc.append(sum_acc/sum_step)\n",
    "            ts_acc.append(acc)\n",
    "            loss_p.append(sum_loss/sum_step)\n",
    "            viz.line(X=np.column_stack((np.array(time_p), np.array(time_p), np.array(time_p))),\n",
    "                     Y=np.column_stack((np.array(loss_p), np.array(tr_acc), np.array(ts_acc))),\n",
    "                     win=line,\n",
    "                     opts=dict(legend=[\"Loss\", \"TRAIN_acc\", \"TEST_acc\"],\n",
    "                     ytickmin=0, ytickmax=2, ytickstep=0.5,\n",
    "                     ))\n",
    "            # visdom text 支持html语句\n",
    "            viz.text(\"<p style='color:red'>epoch:{}</p><br><p style='color:blue'>Loss:{:.4f}</p><br>\"\n",
    "                     \"<p style='color:BlueViolet'>TRAIN_acc:{:.4f}</p><br><p style='color:orange'>TEST_acc:{:.4f}</p><br>\"\n",
    "                     \"<p style='color:green'>Time:{:.2f}</p>\".format(epoch, sum_loss/sum_step, sum_acc/sum_step, acc,\n",
    "                                time.time()-start_time),\n",
    "                     win=text)\n",
    "            sum_loss, sum_acc, sum_step = 0., 0., 0.\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 78 %\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()  # Change to test form, application scenarios such as: dropout\n",
    "correct = 0\n",
    "total = 0\n",
    "for test_features, test_labels in test_loader:\n",
    "    test_features = Variable(test_features)\n",
    "    test_features = test_features.float()\n",
    "    test_labels = Variable(test_labels)\n",
    "\n",
    "    outputs = cnn(test_features)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += test_labels.size(0)\n",
    "    correct += (predicted == test_labels.data).sum()\n",
    "    \n",
    "print(' Test Accuracy: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Trained Model\n",
    "# torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last batch size should be 0\n",
      "outputs has a shape of: torch.Size([32, 9])\n",
      "\tthe 1st item is: torch.Size([9]) tensor([-0.2443,  4.7957, -0.6776, -3.9314, -2.2064,  2.4560,  0.6055, -0.2776,\n",
      "        -1.8728], grad_fn=<SelectBackward0>)\n",
      "predicted has a shape of: torch.Size([32])\n",
      "\tthe 1st item is: torch.Size([]) tensor(1)\n",
      "test_labels has a shape of: torch.Size([32])\n",
      "\tthe 1st item is: torch.Size([]) tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(\"The last batch size should be\", len(shmDS)%batch_size)\n",
    "print(\"outputs has a shape of:\", outputs.shape)\n",
    "print(\"\\tthe 1st item is:\", outputs[1].shape, outputs[1])\n",
    "\n",
    "print(\"predicted has a shape of:\", predicted.shape)\n",
    "print(\"\\tthe 1st item is:\", predicted[1].shape, predicted[1])\n",
    "\n",
    "print(\"test_labels has a shape of:\", test_labels.shape)\n",
    "print(\"\\tthe 1st item is:\", test_labels[1].shape, test_labels[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
