{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9170044d90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "torch.manual_seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Hyper Parameters\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHM_Dataset(Dataset):\n",
    "    \"\"\" Prepare dataset for pytorch\n",
    "        Ref: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, case, data_file, transform): \n",
    "        self.case = case\n",
    "        self.data_file = Path(data_file)\n",
    "        self.data_df = pd.read_json(self.data_file, dtype=np.array)\n",
    "        # self.data = self.data_df.cat()\n",
    "        self.data = self.data_df.stack()\n",
    "        self.labels = pd.DataFrame([self.case,]*self.data_df.shape[0]*self.data_df.shape[1])\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.labels.iloc[index])\n",
    "        feature = np.array(self.data.iloc[index])\n",
    "\n",
    "        # trans1 = transforms.ToTensor()\n",
    "        # feature_tr1 = trans1(feature)\n",
    "        # mean, std = feature_tr1.mean(), feature_tr1.std()\n",
    "        mean, std = feature.mean(), feature.std()\n",
    "\n",
    "        trans2 = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        feature_tr2 = trans2(feature)\n",
    "        # print(f\"feature: {feature.shape}, label: {label.shape}\")\n",
    "        return feature_tr2, label\n",
    "\n",
    "\n",
    "# shmDS = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm01s.json\")\n",
    "# print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target span needs to be 0 to N-1 [Ref: IndexError: Target is out of bounds](https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# trans = transforms.ToTensor()\n",
    "\n",
    "shmDS_1 = SHM_Dataset(0, \"~/Codes/homework/data/SHM/shm01s.json\", trans) # Case 1\n",
    "shmDS_2 = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm02s.json\", trans)\n",
    "shmDS_3 = SHM_Dataset(2, \"~/Codes/homework/data/SHM/shm03s.json\", trans)\n",
    "shmDS_4 = SHM_Dataset(3, \"~/Codes/homework/data/SHM/shm04s.json\", trans)\n",
    "shmDS_5 = SHM_Dataset(4, \"~/Codes/homework/data/SHM/shm05s.json\", trans)\n",
    "shmDS_6 = SHM_Dataset(5, \"~/Codes/homework/data/SHM/shm06s.json\", trans)\n",
    "shmDS_7 = SHM_Dataset(6, \"~/Codes/homework/data/SHM/shm07s.json\", trans)\n",
    "shmDS_8 = SHM_Dataset(7, \"~/Codes/homework/data/SHM/shm08s.json\", trans)\n",
    "shmDS_9 = SHM_Dataset(8, \"~/Codes/homework/data/SHM/shm09s.json\", trans)\n",
    "shmDS = shmDS_1 + shmDS_2 + shmDS_3 + shmDS_4 + shmDS_5 + shmDS_6 + shmDS_7 + shmDS_8 + shmDS_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 24672 samples in the given dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on a single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 16, 16])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: torch.Size([16, 16])\n",
      "\ttensor([[ 5.5516e-01,  6.2368e-01,  4.2368e-01,  9.3117e-01,  6.3285e-01,\n",
      "          9.8631e-01,  1.2433e+00, -9.8477e-03, -3.7773e-01, -1.8511e-01,\n",
      "         -7.1862e-01, -3.5220e-01,  1.2368e-03, -1.1133e+00, -1.3985e+00,\n",
      "         -6.3449e-01],\n",
      "        [ 9.0763e-02,  1.1027e+00,  1.1144e+00,  4.0309e-01,  4.3811e-01,\n",
      "          5.8182e-01,  4.1986e-01,  8.9983e-01,  9.0958e-01, -2.1383e-01,\n",
      "         -1.2979e+00, -1.8109e+00, -1.8109e+00, -1.4243e+00, -8.1952e-01,\n",
      "          3.4345e-01],\n",
      "        [ 1.3924e+00,  1.1609e+00,  8.5826e-01,  1.4659e+00,  1.0880e+00,\n",
      "         -1.9488e-01, -3.9916e-01, -2.5583e-01, -5.5284e-01, -6.7517e-01,\n",
      "         -8.0931e-01, -1.4433e+00, -1.0330e+00, -1.7811e-01,  1.9588e-01,\n",
      "          1.2078e+00],\n",
      "        [ 1.5976e+00,  9.1703e-01,  4.2731e-01,  1.9632e-01,  3.0597e-01,\n",
      "          5.7366e-02, -4.5208e-01, -3.8428e-01,  1.5819e-02, -3.0088e-01,\n",
      "         -1.1479e+00, -1.3838e+00, -1.3898e+00, -5.7165e-01,  9.7723e-01,\n",
      "          1.6702e+00],\n",
      "        [ 1.4796e+00,  8.1765e-01,  5.0270e-01,  6.7575e-01, -7.2542e-02,\n",
      "         -6.1466e-01, -5.9498e-01, -1.2747e+00, -1.3145e+00, -7.6849e-01,\n",
      "         -7.3131e-01,  3.1853e-02,  9.1694e-01,  7.2688e-01,  1.1371e+00,\n",
      "          1.9803e+00],\n",
      "        [ 6.7241e-01, -6.3770e-01, -1.4939e-01, -6.8758e-02, -4.8197e-01,\n",
      "         -8.6764e-01, -1.3046e+00, -2.2331e-01,  7.6290e-01,  2.6938e-01,\n",
      "         -3.9288e-01, -7.1279e-01, -1.0804e+00, -1.2387e-01,  2.0892e+00,\n",
      "          2.4385e+00],\n",
      "        [ 1.1144e+00,  3.0641e-01, -3.8443e-01, -1.2405e+00, -1.2129e+00,\n",
      "         -1.2763e+00, -1.4897e+00, -8.4110e-01,  1.0228e-01,  4.7967e-01,\n",
      "          5.0805e-01,  2.5800e-01,  6.9572e-01,  1.8561e+00,  1.8655e+00,\n",
      "          1.0680e+00],\n",
      "        [ 3.5350e-02, -1.4375e+00, -1.4173e+00, -8.9359e-01, -1.5961e+00,\n",
      "         -1.5769e+00,  2.6807e-01,  1.2448e+00,  1.1931e+00,  9.3863e-01,\n",
      "         -1.4385e-01, -8.7245e-01, -6.4936e-01,  6.0638e-01,  2.2378e+00,\n",
      "          1.5207e+00],\n",
      "        [-6.0227e-01, -1.2219e+00, -1.2988e+00, -1.2139e+00, -6.1568e-01,\n",
      "         -7.4662e-01, -4.7993e-01,  5.2831e-01,  6.1555e-01,  6.2473e-01,\n",
      "          7.9338e-01,  5.8784e-01,  1.1566e+00,  1.6975e+00,  8.6935e-01,\n",
      "         -7.5960e-01],\n",
      "        [-1.5913e+00, -1.8292e+00, -1.4946e+00, -1.1890e+00, -5.1639e-01,\n",
      "          8.0877e-01,  1.1821e+00,  1.3731e+00,  1.1746e+00, -3.9507e-01,\n",
      "         -1.2998e+00, -3.9143e-01,  7.5344e-01,  1.2460e+00,  8.2406e-01,\n",
      "         -6.8771e-01],\n",
      "        [-1.4057e+00, -1.3746e+00, -1.1295e+00, -1.2621e-01,  3.7567e-01,\n",
      "          1.4369e-01,  8.2635e-01,  1.3676e+00,  6.1230e-01,  2.6616e-01,\n",
      "          6.4164e-01,  4.0002e-01, -5.8399e-02, -2.1573e-01, -3.6985e-01,\n",
      "         -1.0884e+00],\n",
      "        [-1.4987e+00, -8.3425e-01, -3.1663e-01, -6.9165e-01, -3.1240e-01,\n",
      "          1.6697e+00,  2.6623e+00,  1.3379e+00,  1.4530e-01, -7.9196e-01,\n",
      "         -1.5856e+00, -2.4518e-01,  1.1292e+00, -5.0526e-02, -1.6120e+00,\n",
      "         -1.2562e+00],\n",
      "        [-3.1751e-01,  3.1997e-01,  4.4241e-01,  3.2347e-01,  6.0724e-01,\n",
      "          5.2697e-01,  4.8034e-01,  9.4560e-01,  5.5287e-01,  3.6229e-02,\n",
      "          1.2576e-01, -3.5074e-02, -7.2212e-01, -1.1776e+00, -9.6693e-01,\n",
      "         -1.2110e-01],\n",
      "        [ 6.2622e-02, -8.6501e-01, -7.9473e-01, -2.2098e-01,  7.3309e-01,\n",
      "          2.5527e+00,  2.8365e+00,  4.7834e-01, -1.6614e+00, -1.7932e+00,\n",
      "         -9.9391e-01,  1.1882e-02,  7.9448e-03, -5.3607e-01, -8.0844e-01,\n",
      "         -9.5002e-01],\n",
      "        [ 3.1413e-02,  1.1091e+00,  9.9481e-01,  6.5530e-01,  1.1483e+00,\n",
      "          1.0114e+00,  3.4870e-01, -2.7682e-01, -5.8433e-01, -7.3218e-01,\n",
      "         -4.2395e-01, -1.6835e-01, -5.8506e-01, -9.1065e-01, -3.6314e-01,\n",
      "          1.5492e-01],\n",
      "        [ 2.8337e-01, -2.2696e-01, -8.6429e-01,  3.7071e-01,  2.2875e+00,\n",
      "          2.2314e+00,  6.9018e-01, -7.4005e-01, -2.1444e+00, -2.3399e+00,\n",
      "         -6.1626e-01,  3.7115e-01, -3.9376e-01, -7.9983e-01, -1.3345e-02,\n",
      "          6.4976e-01]], dtype=torch.float64)\n",
      "Label: torch.Size([])\n",
      "\t2\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(shmDS, batch_size=batch_size, shuffle=True) # split samples into mini-batches and reshuffle the data to reduce overfitting\n",
    "test_loader = DataLoader(shmDS, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "# train_features = train_features.unsqueeze(dim=1)\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "fig, axis = plt.subplots()\n",
    "axis.imshow(img, cmap=\"gray\")\n",
    "\n",
    "axis.set(title=f\"Label: {label}\", xticks=range(16), yticks=range(16))\n",
    "plt.show()\n",
    "print(f\"Input features: {img.shape}\\n\\t{img}\")\n",
    "print(f\"Label: {label.shape}\\n\\t{label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the neural network\n",
    "\n",
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four-layer convolution\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ## by HB\n",
    "        # self.conv1 = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 4, kernel_size=4, padding=1),\n",
    "        #     nn.BatchNorm2d(4),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2))\n",
    "        # self.conv2 = nn.Sequential(\n",
    "        #     nn.Conv2d(4, 8, kernel_size=4, padding=1),\n",
    "        #     nn.BatchNorm2d(8),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2))\n",
    "        # self.fc = nn.Linear(3*3*8, 9)\n",
    "        \n",
    "        ## by Chen\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(32 * 1 * 1, 9)\n",
    "        self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        x = self.prob(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func = nn.CrossEntropyLoss()\n",
    "loss_func = nn.NLLLoss()\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [100/771], Loss: 1.1111\n",
      "Epoch [1/2], Iter [200/771], Loss: 1.4366\n",
      "Epoch [1/2], Iter [300/771], Loss: 1.0957\n",
      "Epoch [1/2], Iter [400/771], Loss: 0.7130\n",
      "Epoch [1/2], Iter [500/771], Loss: 1.2592\n",
      "Epoch [1/2], Iter [600/771], Loss: 0.5292\n",
      "Epoch [1/2], Iter [700/771], Loss: 0.7024\n",
      "Epoch [2/2], Iter [100/771], Loss: 0.7622\n",
      "Epoch [2/2], Iter [200/771], Loss: 0.6553\n",
      "Epoch [2/2], Iter [300/771], Loss: 0.5501\n",
      "Epoch [2/2], Iter [400/771], Loss: 0.3721\n",
      "Epoch [2/2], Iter [500/771], Loss: 0.6898\n",
      "Epoch [2/2], Iter [600/771], Loss: 0.8655\n",
      "Epoch [2/2], Iter [700/771], Loss: 0.4640\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (train_features, train_labels) in enumerate(train_loader):\n",
    "        train_features = Variable(train_features)\n",
    "        # images = images.unsqueeze(dim=1)\n",
    "        train_features = train_features.float()\n",
    "        train_labels = Variable(train_labels)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(train_features) # shape(outputs) -> (batch_size, seq_len, n_classes)\n",
    "        loss = loss_func(torch.log(outputs), train_labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, len(shmDS) // batch_size, loss.item()))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 77 %\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()  # Change to test form, application scenarios such as: dropout\n",
    "correct = 0\n",
    "total = 0\n",
    "for test_features, test_labels in test_loader:\n",
    "    test_features = Variable(test_features)\n",
    "    test_features = test_features.float()\n",
    "    test_labels = Variable(test_labels)\n",
    "\n",
    "    outputs = cnn(test_features)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += test_labels.size(0)\n",
    "    correct += (predicted == test_labels.data).sum()\n",
    "    \n",
    "print(' Test Accuracy: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Trained Model\n",
    "# torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last batch size should be 0\n",
      "outputs has a shape of: torch.Size([32, 9])\n",
      "\tthe 1st item is: torch.Size([9]) tensor([8.8839e-05, 9.7836e-01, 2.0634e-04, 1.4881e-05, 2.3657e-05, 1.4286e-03,\n",
      "        1.9793e-02, 5.6836e-05, 3.0250e-05], grad_fn=<SelectBackward0>)\n",
      "predicted has a shape of: torch.Size([32])\n",
      "\tthe 1st item is: torch.Size([]) tensor(1)\n",
      "test_labels has a shape of: torch.Size([32])\n",
      "\tthe 1st item is: torch.Size([]) tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(\"The last batch size should be\", len(shmDS)%batch_size)\n",
    "print(\"outputs has a shape of:\", outputs.shape)\n",
    "print(\"\\tthe 1st item is:\", outputs[1].shape, outputs[1])\n",
    "\n",
    "print(\"predicted has a shape of:\", predicted.shape)\n",
    "print(\"\\tthe 1st item is:\", predicted[1].shape, predicted[1])\n",
    "\n",
    "print(\"test_labels has a shape of:\", test_labels.shape)\n",
    "print(\"\\tthe 1st item is:\", test_labels[1].shape, test_labels[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
