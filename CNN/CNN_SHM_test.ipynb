{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fce3a2c71f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Hyper Parameters\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHM_Dataset(Dataset):\n",
    "    \"\"\" Prepare dataset for pytorch\n",
    "        Ref: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, case, data_file, transform): \n",
    "        self.case = case\n",
    "        self.data_file = Path(data_file)\n",
    "        self.data_df = pd.read_json(self.data_file, dtype=np.array)\n",
    "        # self.data = self.data_df.cat()\n",
    "        self.data = self.data_df.stack()\n",
    "        self.labels = pd.DataFrame([self.case,]*self.data_df.shape[0]*self.data_df.shape[1])\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.labels.iloc[index])\n",
    "        feature = np.array(self.data.iloc[index])\n",
    "\n",
    "        # trans1 = transforms.ToTensor()\n",
    "        # feature_tr1 = trans1(feature)\n",
    "        # mean, std = feature_tr1.mean(), feature_tr1.std()\n",
    "        mean, std = feature.mean(), feature.std()\n",
    "\n",
    "        trans2 = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        feature_tr2 = trans2(feature)\n",
    "        # print(f\"feature: {feature.shape}, label: {label.shape}\")\n",
    "        return feature_tr2, label\n",
    "\n",
    "\n",
    "# shmDS = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm01s.json\")\n",
    "# print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target span needs to be 0 to N-1 [Ref: IndexError: Target is out of bounds](https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# trans = transforms.ToTensor()\n",
    "\n",
    "shmDS_1 = SHM_Dataset(0, \"~/Codes/homework/data/SHM/shm01s.json\", trans) # Case 1\n",
    "shmDS_2 = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm02s.json\", trans)\n",
    "shmDS_3 = SHM_Dataset(2, \"~/Codes/homework/data/SHM/shm03s.json\", trans)\n",
    "shmDS_4 = SHM_Dataset(3, \"~/Codes/homework/data/SHM/shm04s.json\", trans)\n",
    "shmDS_5 = SHM_Dataset(4, \"~/Codes/homework/data/SHM/shm05s.json\", trans)\n",
    "shmDS_6 = SHM_Dataset(5, \"~/Codes/homework/data/SHM/shm06s.json\", trans)\n",
    "shmDS_7 = SHM_Dataset(6, \"~/Codes/homework/data/SHM/shm07s.json\", trans)\n",
    "shmDS_8 = SHM_Dataset(7, \"~/Codes/homework/data/SHM/shm08s.json\", trans)\n",
    "shmDS_9 = SHM_Dataset(8, \"~/Codes/homework/data/SHM/shm09s.json\", trans)\n",
    "shmDS = shmDS_1 + shmDS_2 + shmDS_3 + shmDS_4 + shmDS_5 + shmDS_6 + shmDS_7 + shmDS_8 + shmDS_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on a single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 16, 16])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: torch.Size([16, 16])\n",
      "\ttensor([[ 6.7114e-01, -2.0169e-01, -8.5230e-01, -1.5905e+00, -1.7916e+00,\n",
      "         -7.9202e-01, -9.4026e-01, -5.7980e-01,  1.6127e+00,  2.0439e+00,\n",
      "          8.1492e-01,  8.0955e-01,  1.1132e+00, -3.3825e-01, -1.1252e+00,\n",
      "         -9.8640e-01],\n",
      "        [-7.8546e-01, -3.0278e-02,  4.4216e-01, -1.9759e-01, -1.6787e-01,\n",
      "          1.4155e-01,  2.3587e-01,  3.0108e-01, -3.9506e-01, -1.9205e-02,\n",
      "          1.1261e+00,  6.1887e-01, -2.4312e-01,  3.6574e-02,  3.2527e-01,\n",
      "         -3.2656e-01],\n",
      "        [-8.5537e-01, -1.0737e+00, -1.2105e+00, -3.9526e-01, -7.8465e-02,\n",
      "         -1.6765e-01,  9.8880e-01,  1.9847e+00,  1.5541e+00,  6.6334e-01,\n",
      "          1.2002e-01, -4.6149e-01, -1.2113e+00, -1.3516e+00, -7.1165e-01,\n",
      "         -3.7619e-01],\n",
      "        [ 2.3033e-01,  7.0836e-01,  2.5084e-01, -2.8187e-01,  3.3840e-01,\n",
      "          7.4195e-01, -2.7817e-01, -2.4434e-01,  1.0103e+00,  4.2671e-01,\n",
      "         -6.9708e-01, -2.4250e-01,  1.1551e-01, -3.2041e-01, -2.2629e-01,\n",
      "         -9.8722e-01],\n",
      "        [-1.2165e+00,  2.1476e-01,  7.0970e-01,  3.3430e-01,  5.8258e-01,\n",
      "          1.4855e+00,  1.4375e+00,  3.3224e-01, -3.5876e-01, -7.9345e-01,\n",
      "         -1.4231e+00, -1.5673e+00, -9.1955e-01, -4.3393e-02,  3.5495e-01,\n",
      "          9.1637e-01],\n",
      "        [ 8.7028e-01, -9.5679e-02,  4.1018e-01,  1.3125e+00, -1.3915e-01,\n",
      "         -1.2148e+00,  3.0420e-02,  3.2466e-01, -3.0852e-01,  1.9445e-01,\n",
      "         -2.0722e-01, -7.9181e-01,  4.1367e-01, -1.3977e-01, -1.8691e+00,\n",
      "          6.4041e-02],\n",
      "        [ 1.2746e+00,  4.9282e-01,  1.1589e+00,  1.7105e+00,  7.2260e-01,\n",
      "          9.3160e-02, -6.4151e-01, -2.1789e+00, -2.0051e+00, -7.0693e-01,\n",
      "         -5.7098e-01, -2.0662e-01,  1.2598e+00,  1.4599e+00,  7.1736e-01,\n",
      "          5.5678e-01],\n",
      "        [ 4.7965e-01,  2.9349e-01,  8.5984e-02, -7.3440e-01, -1.3682e+00,\n",
      "         -9.3186e-01, -2.6669e-01, -1.9608e-02,  6.1215e-01,  6.8511e-01,\n",
      "          6.9277e-01,  6.5689e-01, -9.4683e-01, -1.4080e+00,  5.5719e-01,\n",
      "          7.3215e-01],\n",
      "        [ 1.3479e-01,  1.1740e+00,  1.2386e+00, -3.0052e-01, -1.0742e+00,\n",
      "         -1.3491e+00, -1.5695e+00, -4.9040e-01,  1.5714e-01, -2.9027e-01,\n",
      "          8.7006e-02,  1.2477e+00,  1.4637e+00,  9.1167e-01,  1.0438e+00,\n",
      "          8.6209e-01],\n",
      "        [-7.8278e-01, -1.6282e+00, -1.7129e+00, -1.9946e+00, -3.2698e-01,\n",
      "          1.2273e+00,  8.7620e-01,  4.4404e-01,  9.5830e-01,  9.9243e-01,\n",
      "         -8.4606e-02, -6.0194e-01,  3.6359e-02,  2.5146e-01,  2.3218e-03,\n",
      "          2.0225e-01],\n",
      "        [-4.7505e-02, -7.3973e-01, -4.6599e-01, -4.1555e-01, -9.0930e-01,\n",
      "         -2.4086e-01,  1.5652e-02,  2.1290e-01,  7.0218e-01,  1.0825e+00,\n",
      "          1.5819e+00,  1.3915e+00,  2.0570e-02, -4.4529e-01, -7.0262e-01,\n",
      "         -2.0344e+00],\n",
      "        [-2.0422e+00, -1.0438e+00, -5.6073e-01,  9.6972e-01,  1.6446e+00,\n",
      "          6.9210e-01,  1.1565e+00,  1.3544e+00, -3.3557e-02, -3.8173e-01,\n",
      "         -1.3051e-02, -8.6029e-01, -1.2899e+00, -6.7699e-01, -4.9470e-01,\n",
      "         -6.1076e-01],\n",
      "        [ 4.0830e-01,  7.1951e-01, -8.6259e-02,  2.6519e-01,  6.3284e-01,\n",
      "         -1.6330e-02,  3.2589e-01,  9.9418e-01,  1.2162e+00,  1.3320e+00,\n",
      "          1.8111e-02, -1.7590e+00, -1.8843e+00, -2.0785e+00, -2.0565e+00,\n",
      "          2.8364e-02],\n",
      "        [ 5.4133e-01,  9.6690e-01,  2.4073e+00,  1.7167e+00,  4.4915e-01,\n",
      "          1.2348e+00,  4.8852e-01, -1.3729e+00, -1.2411e+00, -1.6212e+00,\n",
      "         -2.2159e+00, -1.3698e+00, -6.4110e-01,  6.3638e-02,  1.6372e+00,\n",
      "          2.3834e+00],\n",
      "        [ 1.4648e+00,  2.0471e-01,  2.0778e-01, -3.1733e-01, -8.6029e-01,\n",
      "         -5.1805e-02,  2.7648e-01, -3.3252e-01, -2.4208e-01, -7.0959e-01,\n",
      "         -1.9042e+00, -1.1480e+00, -1.8200e-01,  3.5294e-01,  1.1343e+00,\n",
      "          1.5229e+00],\n",
      "        [ 1.2902e+00,  1.7085e+00,  1.4473e+00, -5.9599e-02, -1.2199e+00,\n",
      "         -1.3815e+00, -1.7846e+00, -2.2946e+00, -1.9202e+00, -1.8242e-01,\n",
      "          6.0355e-01,  9.5830e-01,  2.0668e+00,  1.6255e+00,  1.1080e+00,\n",
      "          1.1627e+00]], dtype=torch.float64)\n",
      "Label: torch.Size([])\n",
      "\t3\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(shmDS, batch_size=batch_size, shuffle=True) # split samples into mini-batches and reshuffle the data to reduce overfitting\n",
    "test_loader = DataLoader(shmDS, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "# train_features = train_features.unsqueeze(dim=1)\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "fig, axis = plt.subplots()\n",
    "axis.imshow(img, cmap=\"gray\")\n",
    "\n",
    "axis.set(title=f\"Label: {label}\", xticks=range(16), yticks=range(16))\n",
    "plt.show()\n",
    "print(f\"Input features: {img.shape}\\n\\t{img}\")\n",
    "print(f\"Label: {label.shape}\\n\\t{label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the neural network\n",
    "\n",
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four-layer convolution\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ## by HB\n",
    "        # self.conv1 = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 4, kernel_size=4, padding=1),\n",
    "        #     nn.BatchNorm2d(4),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2))\n",
    "        # self.conv2 = nn.Sequential(\n",
    "        #     nn.Conv2d(4, 8, kernel_size=4, padding=1),\n",
    "        #     nn.BatchNorm2d(8),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2))\n",
    "        # self.fc = nn.Linear(3*3*8, 9)\n",
    "        \n",
    "        ## by Chen\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(32 * 1 * 1, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (train_features, train_labels) in enumerate(train_loader):\n",
    "        train_features = Variable(train_features)\n",
    "        # images = images.unsqueeze(dim=1)\n",
    "        train_features = train_features.float()\n",
    "        train_labels = Variable(train_labels)\n",
    "        # print(type(images), images)\n",
    "        # print(type(labels), labels)\n",
    "        # print(\"[ OK ] at this step\") \n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(train_features)\n",
    "        loss = loss_func(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, len(shmDS) // batch_size, loss.item()))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()  # Change to test form, application scenarios such as: dropout\n",
    "correct = 0\n",
    "total = 0\n",
    "for test_features, test_labels in test_loader:\n",
    "    test_features = Variable(test_features)\n",
    "    test_features = test_features.float()\n",
    "    test_labels = Variable(test_labels)\n",
    "\n",
    "    outputs = cnn(test_features)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += test_labels.size(0)\n",
    "    correct += (predicted == test_labels.data).sum()\n",
    "    \n",
    "print(' Test Accuracy: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Trained Model\n",
    "# torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The last batch size should be\", len(shmDS)%batch_size)\n",
    "print(\"outputs has a shape of:\", outputs.shape)\n",
    "print(\"\\tthe 1st item is:\", outputs[1].shape, outputs[1])\n",
    "\n",
    "print(\"predicted has a shape of:\", predicted.shape)\n",
    "print(\"\\tthe 1st item is:\", predicted[1].shape, predicted[1])\n",
    "\n",
    "print(\"test_labels has a shape of:\", test_labels.shape)\n",
    "print(\"\\tthe 1st item is:\", test_labels[1].shape, test_labels[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
