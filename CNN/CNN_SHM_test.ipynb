{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHM_Dataset(Dataset):\n",
    "    \"\"\" Prepare dataset for pytorch\n",
    "        Ref: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, case, data_file,transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])): \n",
    "        self.case = case\n",
    "        self.data_file = Path(data_file)\n",
    "        self.data_df = pd.read_json(self.data_file, dtype=np.array)\n",
    "        # self.data = self.data_df.cat()\n",
    "        self.data = self.data_df.stack()\n",
    "        self.labels = pd.DataFrame([self.case,]*self.data_df.shape[0]*self.data_df.shape[1])\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = np.array(self.labels.iloc[index])\n",
    "        feature = np.array(self.data.iloc[index])\n",
    "        feature = self.transform(feature)\n",
    "        # print(f\"feature: {feature.shape}, label: {label.shape}\")\n",
    "        return feature, label\n",
    "\n",
    "\n",
    "# shmDS = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm01s.json\")\n",
    "# print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shmDS_1 = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm01s.json\")\n",
    "shmDS_2 = SHM_Dataset(2, \"~/Codes/homework/data/SHM/shm02s.json\")\n",
    "shmDS_3 = SHM_Dataset(3, \"~/Codes/homework/data/SHM/shm03s.json\")\n",
    "shmDS_4 = SHM_Dataset(4, \"~/Codes/homework/data/SHM/shm04s.json\")\n",
    "shmDS_5 = SHM_Dataset(5, \"~/Codes/homework/data/SHM/shm05s.json\")\n",
    "shmDS_6 = SHM_Dataset(6, \"~/Codes/homework/data/SHM/shm06s.json\")\n",
    "shmDS_7 = SHM_Dataset(7, \"~/Codes/homework/data/SHM/shm07s.json\")\n",
    "shmDS_8 = SHM_Dataset(8, \"~/Codes/homework/data/SHM/shm08s.json\")\n",
    "shmDS_9 = SHM_Dataset(9, \"~/Codes/homework/data/SHM/shm09s.json\")\n",
    "shmDS = shmDS_1 + shmDS_2 + shmDS_3 + shmDS_4 + shmDS_5 + shmDS_6 + shmDS_7 + shmDS_8 + shmDS_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 3744 samples in the given dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There is\", len(shmDS_6), \"samples in the given dataset\")\n",
    "# print(shmDS_6.__getitem__(11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on a single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([4, 1, 16, 16])\n",
      "Labels batch shape: torch.Size([4, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(shmDS, batch_size=4, shuffle=True) # split samples into mini-batches and reshuffle the data to reduce overfitting\n",
    "test_loader = DataLoader(shmDS, batch_size=4, shuffle=False)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "# train_features = train_features.unsqueeze(dim=1)\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "fig, axis = plt.subplots()\n",
    "axis.imshow(img, cmap=\"gray\")\n",
    "\n",
    "axis.set(title=f\"Label: {label}\", xticks=range(16), yticks=range(8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the neural network\n",
    "\n",
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-layer convolution\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Quick build with sequence tools\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(32 * 1 * 1, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 32 * 1 * 1) \n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 1\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Iter [100/6168] Loss: 0.0185\n",
      "Epoch [1/1], Iter [200/6168] Loss: 0.0070\n",
      "Epoch [1/1], Iter [300/6168] Loss: 0.0037\n",
      "Epoch [1/1], Iter [400/6168] Loss: 0.0024\n",
      "Epoch [1/1], Iter [500/6168] Loss: 0.0017\n",
      "Epoch [1/1], Iter [600/6168] Loss: 0.0012\n",
      "Epoch [1/1], Iter [700/6168] Loss: 0.0010\n",
      "Epoch [1/1], Iter [800/6168] Loss: 0.0008\n",
      "Epoch [1/1], Iter [900/6168] Loss: 0.0006\n",
      "Epoch [1/1], Iter [1000/6168] Loss: 0.0005\n",
      "Epoch [1/1], Iter [1100/6168] Loss: 0.0006\n",
      "Epoch [1/1], Iter [1200/6168] Loss: 0.0004\n",
      "Epoch [1/1], Iter [1300/6168] Loss: 0.0003\n",
      "Epoch [1/1], Iter [1400/6168] Loss: 0.0005\n",
      "Epoch [1/1], Iter [1500/6168] Loss: 0.0002\n",
      "Epoch [1/1], Iter [1600/6168] Loss: 0.0003\n",
      "Epoch [1/1], Iter [1700/6168] Loss: 0.0003\n",
      "Epoch [1/1], Iter [1800/6168] Loss: 0.0002\n",
      "Epoch [1/1], Iter [1900/6168] Loss: 0.0002\n",
      "Epoch [1/1], Iter [2000/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [2100/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [2200/6168] Loss: 0.0004\n",
      "Epoch [1/1], Iter [2300/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [2400/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [2500/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [2600/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [2700/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [2800/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [2900/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [3000/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [3100/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [3200/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [3300/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [3400/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [3500/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [3600/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [3700/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [3800/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [3900/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4000/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4100/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4200/6168] Loss: 0.0001\n",
      "Epoch [1/1], Iter [4300/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4400/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4500/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4600/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4700/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4800/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [4900/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5000/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5100/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5200/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5300/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5400/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5500/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5600/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5700/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5800/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [5900/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [6000/6168] Loss: 0.0000\n",
      "Epoch [1/1], Iter [6100/6168] Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (train_features, train_labels) in enumerate(train_loader):\n",
    "        train_features = Variable(train_features)\n",
    "        # images = images.unsqueeze(dim=1)\n",
    "        train_features = train_features.float()\n",
    "        train_labels = Variable(train_labels)\n",
    "        # print(type(images), images)\n",
    "        # print(type(labels), labels)\n",
    "        # print(\"[ OK ] at this step\") \n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(train_features)\n",
    "        # loss = loss_func(outputs, labels)\n",
    "        loss = loss_func(outputs, torch.max(train_labels, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, len(shmDS) // batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 66 %\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()  # Change to test form, application scenarios such as: dropout\n",
    "correct = 0\n",
    "total = 0\n",
    "for test_features, test_labels in test_loader:\n",
    "    test_features = Variable(test_features)\n",
    "    # images = images.unsqueeze(dim=1)\n",
    "    test_features = test_features.float()\n",
    "    test_labels = Variable(test_labels)\n",
    "    # print(x.shape)\n",
    "\n",
    "\n",
    "    outputs = cnn(test_features)\n",
    "    # print(outputs.type)\n",
    "    _, predicted = torch.max(outputs.data, 0)\n",
    "    # print(outputs.data)\n",
    "    # print(predicted)\n",
    "    predicted = predicted +1\n",
    "    total += test_labels.size(0)\n",
    "    # print('ok for this step', total)\n",
    "    # print(test_labels.data)\n",
    "    correct += (predicted == test_labels.data).sum()\n",
    "    \n",
    "    # print('okkkkkkkkkkkkkk for this step', correct)\n",
    "\n",
    "print(' Test Accuracy: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Trained Model\n",
    "# torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
