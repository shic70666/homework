{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 2992 samples in the given dataset\n"
     ]
    }
   ],
   "source": [
    "class SHM_Dataset(Dataset):\n",
    "    \"\"\" Prepare dataset for pytorch\n",
    "        Ref: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, case, data_file):\n",
    "        self.case = case\n",
    "        self.data_file = Path(data_file)\n",
    "        self.data_df = pd.read_json(self.data_file, dtype=np.array)\n",
    "        self.data = self.data_df.stack()\n",
    "        self.labels = pd.DataFrame([self.case,]*self.data_df.shape[0]*self.data_df.shape[1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = np.array(self.labels.iloc[index])\n",
    "        feature = np.array(self.data.iloc[index])\n",
    "        # print(f\"feature: {feature.shape}, label: {label.shape}\")\n",
    "        return feature, label\n",
    "\n",
    "shmDS = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm01s.json\")\n",
    "print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on a single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 8, 16])\n",
      "Labels batch shape: torch.Size([64, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(shmDS, batch_size=64, shuffle=True) # split samples into mini-batches and reshuffle the data to reduce overfitting\n",
    "test_loader = DataLoader(shmDS, batch_size=64, shuffle=False)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "train_features = train_features.unsqueeze(dim=1)\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "fig, axis = plt.subplots()\n",
    "axis.imshow(img, cmap=\"gray\")\n",
    "axis.set(title=f\"Label: {label}\", xticks=range(16), yticks=range(8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the neural network\n",
    "\n",
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-layer convolution\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Quick build with sequence tools\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=2, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(2 * 4 * 32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = out.view(out.size(0), -1)  # reshape\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        images = images.unsqueeze(dim=1)\n",
    "        images = images.float()\n",
    "        labels = Variable(labels)\n",
    "        # print(type(images), images)\n",
    "        # print(type(labels), labels)\n",
    "        # print(\"[ OK ] at this step\") \n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        # loss = loss_func(outputs, labels)\n",
    "        loss = loss_func(outputs, torch.max(labels, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, len(train_dataset) // batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 0 %\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()  # Change to test form, application scenarios such as: dropout\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images)\n",
    "    images = images.unsqueeze(dim=1)\n",
    "    images = images.float()\n",
    "    labels = Variable(labels)\n",
    "\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.data).sum()\n",
    "\n",
    "print(' Test Accuracy: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Trained Model\n",
    "# torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
