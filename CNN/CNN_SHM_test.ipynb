{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f99c0c0dd90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Hyper Parameters\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHM_Dataset(Dataset):\n",
    "    \"\"\" Prepare dataset for pytorch\n",
    "        Ref: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, case, data_file, transform): \n",
    "        self.case = case\n",
    "        self.data_file = Path(data_file)\n",
    "        self.data_df = pd.read_json(self.data_file, dtype=np.array)\n",
    "        # self.data = self.data_df.cat()\n",
    "        self.data = self.data_df.stack()\n",
    "        self.labels = pd.DataFrame([self.case,]*self.data_df.shape[0]*self.data_df.shape[1])\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.labels.iloc[index])\n",
    "        feature = np.array(self.data.iloc[index])\n",
    "\n",
    "        # trans1 = transforms.ToTensor()\n",
    "        # feature_tr1 = trans1(feature)\n",
    "        # mean, std = feature_tr1.mean(), feature_tr1.std()\n",
    "        mean, std = feature.mean(), feature.std()\n",
    "\n",
    "        trans2 = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        feature_tr2 = trans2(feature)\n",
    "        # print(f\"feature: {feature.shape}, label: {label.shape}\")\n",
    "        return feature_tr2, label\n",
    "\n",
    "\n",
    "# shmDS = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm01s.json\")\n",
    "# print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target span needs to be 0 to N-1 [Ref: IndexError: Target is out of bounds](https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# trans = transforms.ToTensor()\n",
    "\n",
    "shmDS_1 = SHM_Dataset(0, \"~/Codes/homework/data/SHM/shm01s.json\", trans) # Case 1\n",
    "shmDS_2 = SHM_Dataset(1, \"~/Codes/homework/data/SHM/shm02s.json\", trans)\n",
    "shmDS_3 = SHM_Dataset(2, \"~/Codes/homework/data/SHM/shm03s.json\", trans)\n",
    "shmDS_4 = SHM_Dataset(3, \"~/Codes/homework/data/SHM/shm04s.json\", trans)\n",
    "shmDS_5 = SHM_Dataset(4, \"~/Codes/homework/data/SHM/shm05s.json\", trans)\n",
    "shmDS_6 = SHM_Dataset(5, \"~/Codes/homework/data/SHM/shm06s.json\", trans)\n",
    "shmDS_7 = SHM_Dataset(6, \"~/Codes/homework/data/SHM/shm07s.json\", trans)\n",
    "shmDS_8 = SHM_Dataset(7, \"~/Codes/homework/data/SHM/shm08s.json\", trans)\n",
    "shmDS_9 = SHM_Dataset(8, \"~/Codes/homework/data/SHM/shm09s.json\", trans)\n",
    "shmDS = shmDS_1 + shmDS_2 + shmDS_3 + shmDS_4 + shmDS_5 + shmDS_6 + shmDS_7 + shmDS_8 + shmDS_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 24672 samples in the given dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There is\", len(shmDS), \"samples in the given dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on a single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 16, 16])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: torch.Size([16, 16])\n",
      "\ttensor([[-1.8351e+00, -1.4840e+00, -1.0692e+00,  1.1173e-02,  2.0173e+00,\n",
      "          4.4214e-01, -2.0250e+00, -1.1489e+00, -6.1356e-01, -8.5416e-01,\n",
      "          1.1679e+00,  2.5220e+00,  7.8409e-01, -2.6112e-01, -1.9567e-01,\n",
      "         -7.2808e-01],\n",
      "        [ 2.6712e-02,  9.5666e-01,  2.5714e-01, -1.1131e-01, -2.7894e-01,\n",
      "         -1.4273e+00, -1.4631e+00, -2.3086e-01,  3.0422e-01,  1.9526e-01,\n",
      "          8.5145e-01,  6.1298e-01, -2.0938e-01,  1.5888e-01,  3.3639e-01,\n",
      "          1.9480e-01],\n",
      "        [ 5.5841e-01,  1.2744e-01, -7.8847e-01, -3.8050e-01,  2.2415e-01,\n",
      "          7.1855e-01,  3.6820e-01, -8.2138e-01, -1.3975e+00, -2.9768e-01,\n",
      "          7.8436e-01,  4.3849e-01,  3.7780e-01,  7.2650e-01, -5.2779e-01,\n",
      "         -1.2758e+00],\n",
      "        [-3.1651e-01,  6.3875e-01,  8.1279e-01,  5.6609e-01,  3.8547e-01,\n",
      "         -1.4476e-01, -4.5122e-01,  2.7880e-01,  7.4213e-01,  3.2094e-01,\n",
      "         -2.7227e-01, -6.1371e-01, -1.1920e+00, -1.5136e+00, -4.6419e-01,\n",
      "          6.5009e-01],\n",
      "        [ 1.1223e+00,  1.2954e+00,  7.2705e-01, -3.7283e-01, -5.6391e-01,\n",
      "         -2.3644e-01,  8.1555e-02,  6.2596e-01,  1.2371e+00,  7.0950e-01,\n",
      "         -3.7283e-01, -1.2554e+00, -1.7976e+00, -9.5458e-01,  3.2149e-01,\n",
      "          4.8410e-01],\n",
      "        [ 7.4295e-01,  5.2441e-01, -7.3756e-01, -1.2610e+00, -6.1579e-01,\n",
      "          1.1841e+00,  2.1201e+00,  1.3026e+00,  6.9542e-01, -4.2235e-01,\n",
      "         -2.4133e+00, -1.6828e+00,  7.7897e-01,  8.5090e-01,  2.5294e-01,\n",
      "          4.7569e-01],\n",
      "        [-1.0646e+00, -2.4698e+00, -5.1175e-01,  9.2759e-01,  8.5200e-01,\n",
      "          2.1514e+00,  1.8013e+00, -5.5317e-01, -1.3337e+00, -7.9851e-01,\n",
      "         -2.2922e-01,  1.1493e+00,  1.4458e+00, -2.0856e-01, -8.5346e-01,\n",
      "         -8.8680e-01],\n",
      "        [-1.8393e+00, -8.5527e-01,  1.6351e+00,  1.9253e+00,  8.7896e-01,\n",
      "         -2.4622e-01, -1.4724e+00, -1.4075e+00, -1.4211e-01,  8.1032e-01,\n",
      "          2.0096e+00,  1.9139e+00, -4.0653e-02, -1.1630e+00, -1.4910e+00,\n",
      "         -1.5342e+00],\n",
      "        [ 8.7404e-02,  1.4296e+00,  3.9370e-01,  3.3750e-02,  4.8967e-01,\n",
      "         -6.6154e-01, -1.0540e+00, -4.3491e-04, -9.7963e-02, -8.0048e-02,\n",
      "          1.1370e+00,  1.1395e+00, -4.9613e-01, -1.1722e+00, -5.5959e-01,\n",
      "          2.9901e-01],\n",
      "        [ 1.8003e+00,  1.6007e+00, -7.5960e-01, -1.7482e+00, -1.6907e+00,\n",
      "         -1.1132e+00,  5.0640e-01,  1.7157e+00,  1.0936e+00, -4.9766e-01,\n",
      "         -1.3412e+00, -9.8262e-01, -5.7521e-01,  5.5009e-01,  2.0454e+00,\n",
      "          1.8724e+00],\n",
      "        [ 5.2340e-01, -2.0098e-01, -6.6587e-01, -1.3528e+00, -9.9977e-01,\n",
      "         -7.5021e-02,  2.4508e-01,  6.0027e-01,  6.4991e-01, -8.6002e-01,\n",
      "         -1.5029e+00, -2.8982e-01,  4.8839e-01,  1.3370e+00,  1.7616e+00,\n",
      "          1.1593e+00],\n",
      "        [-2.3214e-01, -1.6637e+00, -1.0387e+00,  1.0119e+00,  1.5603e+00,\n",
      "          3.3356e-01, -3.7688e-01, -6.5374e-01, -1.5733e+00, -1.6309e+00,\n",
      "         -1.9220e-01,  5.7075e-01,  1.5575e+00,  1.3226e+00, -5.9418e-01,\n",
      "         -6.8373e-01],\n",
      "        [ 3.8410e-01,  9.4077e-02,  4.6730e-02,  1.2816e+00,  9.7402e-01,\n",
      "         -8.2962e-01, -1.0154e+00, -6.8902e-01, -1.2298e+00, -3.5717e-02,\n",
      "          1.0126e+00,  2.2478e-01, -1.5061e-01, -4.9236e-01, -1.5376e+00,\n",
      "         -9.0855e-01],\n",
      "        [ 1.1309e+00,  2.1582e+00,  1.6399e+00,  5.2898e-01, -1.2427e+00,\n",
      "         -1.7879e+00, -2.3224e-01,  5.3263e-01,  1.9389e-01,  9.9349e-01,\n",
      "          9.8774e-01, -9.2948e-01, -1.7538e+00, -8.4244e-01, -4.7103e-01,\n",
      "          3.1648e-02],\n",
      "        [ 1.5852e+00,  1.1774e+00, -2.4275e-01,  8.0549e-02, -1.4842e-01,\n",
      "         -3.0417e-01,  8.0986e-01,  8.6571e-01, -2.4832e-01, -3.1203e-01,\n",
      "          3.8869e-02, -9.1929e-01, -1.0761e+00,  7.6206e-01,  8.6763e-01,\n",
      "         -2.1743e-01],\n",
      "        [ 2.9654e-01, -2.4017e-02, -9.7006e-01, -7.2194e-01,  2.3594e-01,\n",
      "          8.3418e-01,  1.3734e+00,  7.5118e-01, -2.8744e-01, -5.0422e-01,\n",
      "         -5.5123e-01, -7.9433e-01,  2.2972e-01,  9.5647e-01,  3.7487e-01,\n",
      "         -2.9421e-01]], dtype=torch.float64)\n",
      "Label: torch.Size([])\n",
      "\t7\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(shmDS, batch_size=batch_size, shuffle=True) # split samples into mini-batches and reshuffle the data to reduce overfitting\n",
    "test_loader = DataLoader(shmDS, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "# train_features = train_features.unsqueeze(dim=1)\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "fig, axis = plt.subplots()\n",
    "axis.imshow(img, cmap=\"gray\")\n",
    "\n",
    "axis.set(title=f\"Label: {label}\", xticks=range(16), yticks=range(16))\n",
    "plt.show()\n",
    "print(f\"Input features: {img.shape}\\n\\t{img}\")\n",
    "print(f\"Label: {label.shape}\\n\\t{label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the neural network\n",
    "\n",
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four-layer convolution\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ## by HB\n",
    "        # self.conv1 = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 4, kernel_size=4, padding=1),\n",
    "        #     nn.BatchNorm2d(4),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2))\n",
    "        # self.conv2 = nn.Sequential(\n",
    "        #     nn.Conv2d(4, 8, kernel_size=4, padding=1),\n",
    "        #     nn.BatchNorm2d(8),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2))\n",
    "        # self.fc = nn.Linear(3*3*8, 9)\n",
    "        \n",
    "        ## by Chen\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(32 * 1 * 1, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [100/771], Loss: 1.6231\n",
      "Epoch [1/5], Iter [200/771], Loss: 1.2762\n",
      "Epoch [1/5], Iter [300/771], Loss: 1.0707\n",
      "Epoch [1/5], Iter [400/771], Loss: 0.8717\n",
      "Epoch [1/5], Iter [500/771], Loss: 0.8612\n",
      "Epoch [1/5], Iter [600/771], Loss: 0.8882\n",
      "Epoch [1/5], Iter [700/771], Loss: 0.6024\n",
      "Epoch [2/5], Iter [100/771], Loss: 0.6382\n",
      "Epoch [2/5], Iter [200/771], Loss: 0.5865\n",
      "Epoch [2/5], Iter [300/771], Loss: 0.6786\n",
      "Epoch [2/5], Iter [400/771], Loss: 0.9338\n",
      "Epoch [2/5], Iter [500/771], Loss: 0.5297\n",
      "Epoch [2/5], Iter [600/771], Loss: 0.6635\n",
      "Epoch [2/5], Iter [700/771], Loss: 0.7730\n",
      "Epoch [3/5], Iter [100/771], Loss: 0.7348\n",
      "Epoch [3/5], Iter [200/771], Loss: 0.7714\n",
      "Epoch [3/5], Iter [300/771], Loss: 0.5944\n",
      "Epoch [3/5], Iter [400/771], Loss: 0.9174\n",
      "Epoch [3/5], Iter [500/771], Loss: 0.5424\n",
      "Epoch [3/5], Iter [600/771], Loss: 1.0600\n",
      "Epoch [3/5], Iter [700/771], Loss: 0.4468\n",
      "Epoch [4/5], Iter [100/771], Loss: 0.6460\n",
      "Epoch [4/5], Iter [200/771], Loss: 0.8578\n",
      "Epoch [4/5], Iter [300/771], Loss: 0.5569\n",
      "Epoch [4/5], Iter [400/771], Loss: 0.5848\n",
      "Epoch [4/5], Iter [500/771], Loss: 0.6329\n",
      "Epoch [4/5], Iter [600/771], Loss: 0.8324\n",
      "Epoch [4/5], Iter [700/771], Loss: 0.8952\n",
      "Epoch [5/5], Iter [100/771], Loss: 0.7589\n",
      "Epoch [5/5], Iter [200/771], Loss: 0.7962\n",
      "Epoch [5/5], Iter [300/771], Loss: 0.8758\n",
      "Epoch [5/5], Iter [400/771], Loss: 0.6419\n",
      "Epoch [5/5], Iter [500/771], Loss: 0.8546\n",
      "Epoch [5/5], Iter [600/771], Loss: 0.3738\n",
      "Epoch [5/5], Iter [700/771], Loss: 0.8210\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (train_features, train_labels) in enumerate(train_loader):\n",
    "        train_features = Variable(train_features)\n",
    "        # images = images.unsqueeze(dim=1)\n",
    "        train_features = train_features.float()\n",
    "        train_labels = Variable(train_labels)\n",
    "        # print(type(images), images)\n",
    "        # print(type(labels), labels)\n",
    "        # print(\"[ OK ] at this step\") \n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(train_features)\n",
    "        loss = loss_func(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, len(shmDS) // batch_size, loss.item()))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 76 %\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()  # Change to test form, application scenarios such as: dropout\n",
    "correct = 0\n",
    "total = 0\n",
    "for test_features, test_labels in test_loader:\n",
    "    test_features = Variable(test_features)\n",
    "    test_features = test_features.float()\n",
    "    test_labels = Variable(test_labels)\n",
    "\n",
    "    outputs = cnn(test_features)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += test_labels.size(0)\n",
    "    correct += (predicted == test_labels.data).sum()\n",
    "    \n",
    "print(' Test Accuracy: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Trained Model\n",
    "# torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last batch size should be 0\n",
      "outputs has a shape of: torch.Size([32, 9])\n",
      "\tthe 1st item is: torch.Size([9]) tensor([ 1.8984,  3.5344, -1.3566, -1.9045, -0.1323, -0.0386, -0.6414, -0.4197,\n",
      "        -2.0631], grad_fn=<SelectBackward0>)\n",
      "predicted has a shape of: torch.Size([32])\n",
      "\tthe 1st item is: torch.Size([]) tensor(1)\n",
      "test_labels has a shape of: torch.Size([32])\n",
      "\tthe 1st item is: torch.Size([]) tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(\"The last batch size should be\", len(shmDS)%batch_size)\n",
    "print(\"outputs has a shape of:\", outputs.shape)\n",
    "print(\"\\tthe 1st item is:\", outputs[1].shape, outputs[1])\n",
    "\n",
    "print(\"predicted has a shape of:\", predicted.shape)\n",
    "print(\"\\tthe 1st item is:\", predicted[1].shape, predicted[1])\n",
    "\n",
    "print(\"test_labels has a shape of:\", test_labels.shape)\n",
    "print(\"\\tthe 1st item is:\", test_labels[1].shape, test_labels[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
